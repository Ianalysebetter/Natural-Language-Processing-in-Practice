{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1a13d8",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "In Moodle you will find the file bitcoin.csv, containing Reddit comments of the bitcoinSubreddit from 2022. Read the file into your console.\n",
    "\n",
    "From this data set, we only need the columns “created”, determining the date at which the\n",
    "post was created, “title” containing the title of the post and ”selftext” containing additional\n",
    "text from the post, if any. For our analysis, we want to analyze “title” and “selftext” as one\n",
    "combined entitiy for each text. So for each post, join the two respective strings if there is a\n",
    "selftext.\n",
    "\n",
    "We will now perform a simple sentiment analysis and compare the resulting time series with\n",
    "the actual Bitcoin price, which you can find in bitcoin prices.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d779c193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1640995385</td>\n",
       "      <td>Anyone use a roundup app to invest spare chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1640995487</td>\n",
       "      <td>Maybe I am more pessimistic, so I withdrew Bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1640995629</td>\n",
       "      <td>Can not withdraw [removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1640996258</td>\n",
       "      <td>When sovereign wealth funds? Anyone heard any ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1640996745</td>\n",
       "      <td>Big Money Lost in a Hard Drive [removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      created                                      combined_text\n",
       "0  1640995385  Anyone use a roundup app to invest spare chang...\n",
       "1  1640995487  Maybe I am more pessimistic, so I withdrew Bit...\n",
       "2  1640995629                         Can not withdraw [removed]\n",
       "3  1640996258  When sovereign wealth funds? Anyone heard any ...\n",
       "4  1640996745           Big Money Lost in a Hard Drive [removed]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the bitcoin.csv file\n",
    "bitcoin_comments_path = 'bitcoin.csv'\n",
    "bitcoin_comments_df = pd.read_csv(bitcoin_comments_path, usecols=['created', 'title', 'selftext'])\n",
    "\n",
    "# Combining \"title\" and \"selftext\" into a single entity for each post\n",
    "# Replace NaN values in \"selftext\" with an empty string before joining\n",
    "bitcoin_comments_df['selftext'] = bitcoin_comments_df['selftext'].fillna('')\n",
    "bitcoin_comments_df['combined_text'] = bitcoin_comments_df['title'] + ' ' + bitcoin_comments_df['selftext']\n",
    "\n",
    "# Displaying the first few rows of the dataframe with the combined text\n",
    "bitcoin_comments_df[['created', 'combined_text']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b015bd2",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Apply preprocessing to the given texts. Keep in mind, that we intend to use sentiment dictionaries to analyze the text later. How does this knowledge change your approach to preprocessing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e38101",
   "metadata": {},
   "source": [
    "##### My Appraoch \n",
    "\n",
    "Given that the sentiment analysis will be based on sentiment dictionaries, the preprocessing steps should ensure that the text is normalized in a way that maximizes the match with the dictionary entries without altering the semantic orientation of words. Here's how this knowledge affects our approach:\n",
    "\n",
    "* Case Normalization: Convert all text to lowercase to ensure that word matches are not missed due to case differences.\n",
    "\n",
    "* Tokenization: Split the text into individual words for analysis.\n",
    "\n",
    "* Removing Special Characters and Numbers: Since sentiment dictionaries typically contain words, removing special characters and numbers can help focus on the text content. However, it's important to keep characters that can change the sentiment of a word, like negation (e.g., \"not\").\n",
    "\n",
    "* Lemmatization: Reducing words to their base or dictionary form to increase the chance of matching dictionary entries. Unlike stemming, lemmatization retains the semantic meaning of the word, which is crucial for sentiment analysis.\n",
    "\n",
    "* Negation Handling: Sentiment analysis can be significantly affected by negation. A straightforward approach to preprocessing might remove negations, altering the sentiment. It's essential to retain negation or implement a strategy to handle it effectively.\n",
    "\n",
    "Given these considerations, let's apply the preprocessing steps to the \"combined_text\" column, focusing on case normalization, tokenization, removing special characters (while retaining sentiment-altering ones like negation), and considering lemmatization for word normalization. We'll also discuss how to handle negation in the context of sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205327a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       combined_text  \\\n",
      "0  Anyone use a roundup app to invest spare chang...   \n",
      "1  Maybe I am more pessimistic, so I withdrew Bit...   \n",
      "2                         Can not withdraw [removed]   \n",
      "3  When sovereign wealth funds? Anyone heard any ...   \n",
      "4           Big Money Lost in a Hard Drive [removed]   \n",
      "\n",
      "                                  processed_advanced  \n",
      "0  anyone use a roundup app to invest spare chang...  \n",
      "1  maybe i am more pessimistic so i withdrew bitc...  \n",
      "2                           can not withdraw removed  \n",
      "3  when sovereign wealth funds anyone heard any n...  \n",
      "4             big money lost in a hard drive removed  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Assuming bitcoin_comments_df is already loaded with the necessary 'combined_text' column\n",
    "\n",
    "# A simplified function to handle preprocessing based on your approach\n",
    "def preprocess_text_advanced(text):\n",
    "    # Convert text to lowercase to ensure case normalization\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Tokenization (basic form using split)\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Removing special characters and numbers, but trying to retain sentiment-altering characters like negation\n",
    "    # Note: Advanced negation handling and lemmatization are not fully implemented here due to limitations\n",
    "    tokens = [re.sub(r'[^a-z\\s]', '', token) for token in tokens if re.sub(r'[^a-z\\s]', '', token) != '']\n",
    "    \n",
    "    # Rejoin tokens into a string for compatibility with further processing steps\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Apply the advanced preprocessing function to the combined text column\n",
    "bitcoin_comments_df['processed_advanced'] = bitcoin_comments_df['combined_text'].apply(preprocess_text_advanced)\n",
    "\n",
    "# Display the first few rows to check the preprocessing results\n",
    "print(bitcoin_comments_df[['combined_text', 'processed_advanced']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2625ecd",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "In dictionary.csv you will find a sentiment dictionary. “Positive words” will have positive\n",
    "values while “Negative words” will have negative values.\n",
    "\n",
    "Use this dictionary to calculate the sentiment score of each text, that is sum up all sentiment\n",
    "values to the corresponding words in said text. A negative score will thus indicate a negative\n",
    "text, while a positive value will indicate a positive text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a1f6de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  processed_advanced  sentiment_score\n",
      "0  anyone use a roundup app to invest spare chang...                1\n",
      "1  maybe i am more pessimistic so i withdrew bitc...               -2\n",
      "2                           can not withdraw removed                0\n",
      "3  when sovereign wealth funds anyone heard any n...                4\n",
      "4             big money lost in a hard drive removed               -1\n"
     ]
    }
   ],
   "source": [
    "# Load the sentiment dictionary from the provided CSV file\n",
    "sentiment_dict_path = 'dictionary.csv'\n",
    "sentiment_df = pd.read_csv(sentiment_dict_path)\n",
    "\n",
    "# Convert the sentiment dictionary DataFrame into a Python dictionary for faster lookup\n",
    "sentiment_dict = pd.Series(sentiment_df.sentiment.values, index=sentiment_df.term).to_dict()\n",
    "\n",
    "# Function to calculate sentiment score of a text based on the sentiment dictionary\n",
    "def calculate_sentiment_score(text):\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "    # Calculate sentiment score by summing the sentiment values of the words found in the sentiment dictionary\n",
    "    score = sum(sentiment_dict.get(word, 0) for word in words)\n",
    "    return score\n",
    "\n",
    "# Apply the sentiment score calculation function to the preprocessed text\n",
    "bitcoin_comments_df['sentiment_score'] = bitcoin_comments_df['processed_advanced'].apply(calculate_sentiment_score)\n",
    "\n",
    "# Display the first few rows to check the sentiment scores\n",
    "print(bitcoin_comments_df[['processed_advanced', 'sentiment_score']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747811e2",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "\n",
    "Compare the daily difference in market values in the file bitcoin price.csv and your sentiment\n",
    "scores with a correlation coefficient of your choice. Do the comments explain the behaviour of\n",
    "the bitcoin price evolution well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec406c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Bitcoin price data\n",
    "bitcoin_prices_path = 'bitcoin_prices.csv'\n",
    "bitcoin_prices_df = pd.read_csv(bitcoin_prices_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6488146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'difference'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the column names of the bitcoin_prices_df to identify the correct column names\n",
    "bitcoin_prices_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f1e8b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between daily price difference and sentiment scores: 0.08015353171742567\n"
     ]
    }
   ],
   "source": [
    "# First, ensure the 'created' column is converted to datetime format in bitcoin_comments_df\n",
    "bitcoin_comments_df['created_datetime'] = pd.to_datetime(bitcoin_comments_df['created'], unit='s')\n",
    "\n",
    "# Now, extracting the date part for daily aggregation\n",
    "bitcoin_comments_df['date'] = bitcoin_comments_df['created_datetime'].dt.date\n",
    "\n",
    "# Calculating daily average sentiment score\n",
    "daily_sentiment_score = bitcoin_comments_df.groupby('date')['sentiment_score'].mean().reset_index()\n",
    "daily_sentiment_score['date'] = pd.to_datetime(daily_sentiment_score['date'])\n",
    "\n",
    "# Load and prepare the bitcoin_prices_df again correctly\n",
    "bitcoin_prices_df['Date'] = pd.to_datetime(bitcoin_prices_df['timestamp'])\n",
    "merged_df = pd.merge(bitcoin_prices_df, daily_sentiment_score, left_on='Date', right_on='date', how='inner')\n",
    "\n",
    "# Calculate the correlation between daily price difference ('difference' column) and sentiment scores\n",
    "correlation = merged_df['difference'].corr(merged_df['sentiment_score'])\n",
    "\n",
    "print(\"Correlation between daily price difference and sentiment scores:\", correlation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a3056",
   "metadata": {},
   "source": [
    " \n",
    "The correlation coefficient between daily price difference and sentiment scores is approximately 0.080, indicating a very slight positive relationship between the two variables. This means that as sentiment scores increase (become more positive), there's a slightly positive trend in the daily price difference of Bitcoin, suggesting that more positive sentiment could be associated with higher price movements. However, the correlation is quite weak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1af3ef",
   "metadata": {},
   "source": [
    "### Thank you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba680b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
