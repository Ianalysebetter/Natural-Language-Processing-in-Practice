{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8399cc08",
   "metadata": {},
   "source": [
    "# Task 1 \n",
    "\n",
    "In moodle you will find the file trek.json and characters.csv. The first file contains transcripts of 5 Star Trek tv shows, separated into the individual episodes. The second file contains\n",
    "the name of characters, the tv show they appear in and their respective rank or role in the\n",
    "show.\n",
    "\n",
    "\n",
    "In this exercise, we will investigate, how well Word2Vec models the relationships between characters in the Star Trek franchise and how different window sizes can change the relationships\n",
    "that are being mapped by the model.\n",
    "\n",
    "\n",
    "Please note: The names “obrien” and “tpol” originally contained an apostrophe. For Word2Vec\n",
    "to recognize the characters correctly, you have to remove each apostrophe with an empty string!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f34acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Series</th>\n",
       "      <th>Roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>archer</td>\n",
       "      <td>ENT</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kirk</td>\n",
       "      <td>TOS</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>picard</td>\n",
       "      <td>TNG</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sisko</td>\n",
       "      <td>DS9</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>janeway</td>\n",
       "      <td>VOY</td>\n",
       "      <td>Captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tucker</td>\n",
       "      <td>ENT</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scott</td>\n",
       "      <td>TOS</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>laforge</td>\n",
       "      <td>TNG</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>obrien</td>\n",
       "      <td>DS9</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>torres</td>\n",
       "      <td>VOY</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tpol</td>\n",
       "      <td>ENT</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spock</td>\n",
       "      <td>TOS</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>riker</td>\n",
       "      <td>TNG</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kira</td>\n",
       "      <td>DS9</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chakotay</td>\n",
       "      <td>VOY</td>\n",
       "      <td>First Officers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>trip</td>\n",
       "      <td>ENT</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>scotty</td>\n",
       "      <td>TOS</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>beverly</td>\n",
       "      <td>TNG</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jadzia</td>\n",
       "      <td>DS9</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>harry</td>\n",
       "      <td>VOY</td>\n",
       "      <td>Nicknames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Character Series           Roles\n",
       "0     archer    ENT        Captains\n",
       "1       kirk    TOS        Captains\n",
       "2     picard    TNG        Captains\n",
       "3      sisko    DS9        Captains\n",
       "4    janeway    VOY        Captains\n",
       "5     tucker    ENT       Engineers\n",
       "6      scott    TOS       Engineers\n",
       "7    laforge    TNG       Engineers\n",
       "8     obrien    DS9       Engineers\n",
       "9     torres    VOY       Engineers\n",
       "10      tpol    ENT  First Officers\n",
       "11     spock    TOS  First Officers\n",
       "12     riker    TNG  First Officers\n",
       "13      kira    DS9  First Officers\n",
       "14  chakotay    VOY  First Officers\n",
       "15      trip    ENT       Nicknames\n",
       "16    scotty    TOS       Nicknames\n",
       "17   beverly    TNG       Nicknames\n",
       "18    jadzia    DS9       Nicknames\n",
       "19     harry    VOY       Nicknames"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import re\n",
    "\n",
    "# Load trek.json\n",
    "with open('trek.json') as f:\n",
    "    trek_data = json.load(f)\n",
    "\n",
    "# Load characters.csv\n",
    "characters_df = pd.read_csv('characters.csv')\n",
    "\n",
    "characters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6a204",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "\n",
    "Preprocess the texts so that they are fit for an analysis. Argue the use the preprocessing steps\n",
    "you take for the given analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b6012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few tokens from the first episode: ['the', 'deep', 'space', 'nine', 'transcripts', 'emissary', 'emissary', 'stardate', '46379', '1', 'original', 'airdate', '3', 'jan', '1993', 'on', 'stardate', '43997', 'captain', 'jean', 'luc', 'picard', 'of', 'the', 'federation', 'starship', 'enterprise', 'was', 'kidnapped', 'for', 'six', 'days', 'by', 'an', 'invading', 'force', 'known', 'as', 'the', 'borg', 'surgically', 'altered', 'he', 'was', 'forced', 'to', 'lead', 'an', 'assault', 'on', 'starfleet', 'at', 'wolf', '359', 'saratoga', 'bridge', 'locutus', 'on', 'viewscreen', 'resistance', 'is', 'futile', 'you', 'will', 'disarm', 'your', 'weapons', 'and', 'escort', 'us', 'to', 'sector', 'zero', 'zero', 'one', 'if', 'you', 'attempt', 'to', 'intervene', 'we', 'will', 'destroy', 'you', 'captain', 'a', 'vulcan', 'red', 'alert', 'load', 'all', 'torpedo', 'bays', 'ready', 'phasers', 'move', 'us', 'to', 'position', 'alpha']\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON data from the file\n",
    "filename = 'trek.json'\n",
    "with open(filename, 'r') as file:\n",
    "    trek_data = json.load(file)\n",
    "\n",
    "# List to hold preprocessed sentences (as lists of words)\n",
    "sentences = []\n",
    "\n",
    "# Loop through each show and its episodes\n",
    "for show, episodes in trek_data.items():\n",
    "    for episode_title, episode_text in episodes.items():\n",
    "        # Lowercase and remove specific apostrophes from character names\n",
    "        text = episode_text.lower().replace(\"o'brien\", \"obrien\").replace(\"t'pol\", \"tpol\")\n",
    "        # Tokenize the text, keeping only words\n",
    "        tokens = re.findall(r'\\w+', text)\n",
    "        sentences.append(tokens)\n",
    "\n",
    "# Example: Print the first few tokens from the first episode's processing\n",
    "if sentences:\n",
    "    print(\"First few tokens from the first episode:\", sentences[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0002ee",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "\n",
    "Train a Word2Vec model on all transcripts with a window size of two (i.e. two words in each\n",
    "direction) and a vector dimension of 300. Train another model with the same parameters and\n",
    "only change the window size to ten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39fcef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Assuming `sentences` is already prepared and contains the preprocessed and tokenized transcripts\n",
    "\n",
    "# Train Word2Vec model with a window size of 2\n",
    "model_window_2 = Word2Vec(sentences=sentences, vector_size=300, window=2, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# Train Word2Vec model with a window size of 10\n",
    "model_window_10 = Word2Vec(sentences=sentences, vector_size=300, window=10, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# sg=0 specifies the training algorithm: CBOW (Continuous Bag of Words). \n",
    "# If you prefer to use the Skip-gram model, set sg=1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c2ebbb",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "\n",
    "\n",
    "We will now use the characters from characters.csv and see, how well Word2Vec differentiates the different tv shows. Calculate the cosine similarities of all possible character pairs for\n",
    "both models. Then, calculate the average similarity between all character pairs within each tv\n",
    "show and the average pairwise similarity to all characters of a different tv show. In the end you\n",
    "should have a 5x5 matrix, containing average pairwise similarities between and within all 5 tv\n",
    "shows.\n",
    "\n",
    "\n",
    "What do you notice? Which model does differentiate the characters of a tv show better from\n",
    "other tv shows?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6c12bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_window_2':           ENT       TOS       TNG       DS9       VOY\n",
       " ENT  0.658812  0.530895  0.527138  0.542008  0.563587\n",
       " TOS  0.530895  0.618966  0.483849  0.462472  0.515654\n",
       " TNG  0.527138  0.483849  0.593197  0.517354  0.538675\n",
       " DS9  0.542008  0.462472  0.517354  0.623971  0.546402\n",
       " VOY  0.563587  0.515654  0.538675  0.546402  0.645253,\n",
       " 'model_window_10':           ENT       TOS       TNG       DS9       VOY\n",
       " ENT  0.548281  0.209373  0.154335  0.198789  0.226451\n",
       " TOS  0.209373  0.551053  0.203047  0.119182  0.160095\n",
       " TNG  0.154335  0.203047  0.463180  0.170131  0.254550\n",
       " DS9  0.198789  0.119182  0.170131  0.451880  0.182436\n",
       " VOY  0.226451  0.160095  0.254550  0.182436  0.494807}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations, product\n",
    "\n",
    "# Load characters.csv\n",
    "characters_df = pd.read_csv('characters.csv')\n",
    "\n",
    "# Ensure character names match the preprocessing applied earlier (e.g., removing apostrophes)\n",
    "characters_df['Character'] = characters_df['Character'].str.lower().replace({\"o'brien\": \"obrien\", \"t'pol\": \"tpol\"}, regex=True)\n",
    "\n",
    "# Prepare a list of unique shows\n",
    "shows = characters_df['Series'].unique()\n",
    "\n",
    "# Initialize an empty dictionary to hold similarity matrices for each model\n",
    "similarity_matrices = {'model_window_2': None, 'model_window_10': None}\n",
    "\n",
    "# Function to calculate average similarities (assuming model is already trained)\n",
    "def calculate_average_similarity(model, characters_df):\n",
    "    # Initialize a matrix to store average similarities between shows\n",
    "    avg_similarity_matrix = pd.DataFrame(0, index=shows, columns=shows, dtype=float)\n",
    "    \n",
    "    # Iterate over each combination of shows to calculate average similarities\n",
    "    for show1, show2 in product(shows, repeat=2):\n",
    "        characters1 = characters_df[characters_df['Series'] == show1]['Character'].tolist()\n",
    "        characters2 = characters_df[characters_df['Series'] == show2]['Character'].tolist()\n",
    "        \n",
    "        total_similarity = 0\n",
    "        count = 0\n",
    "        \n",
    "        # Compute cosine similarity for each character pair between the two shows\n",
    "        for char1, char2 in product(characters1, characters2):\n",
    "            try:\n",
    "                similarity = model.wv.similarity(char1, char2)\n",
    "                total_similarity += similarity\n",
    "                count += 1\n",
    "            except KeyError:  # Character not in model vocabulary\n",
    "                continue\n",
    "                \n",
    "        # Calculate average similarity if there were any valid comparisons\n",
    "        if count > 0:\n",
    "            avg_similarity = total_similarity / count\n",
    "        else:\n",
    "            avg_similarity = None  # Indicate no valid comparisons\n",
    "        \n",
    "        avg_similarity_matrix.loc[show1, show2] = avg_similarity\n",
    "    \n",
    "    return avg_similarity_matrix\n",
    "\n",
    "# Assuming 'model_window_2' and 'model_window_10' are your trained Word2Vec models\n",
    "similarity_matrices['model_window_2'] = calculate_average_similarity(model_window_2, characters_df)\n",
    "similarity_matrices['model_window_10'] = calculate_average_similarity(model_window_10, characters_df)\n",
    "\n",
    "# The resulting 'similarity_matrices' dictionary contains the 5x5 matrices for each model\n",
    "\n",
    "similarity_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a93943",
   "metadata": {},
   "source": [
    "The results of the cosine similarity calculations between character pairs for both models, with window sizes of 2 and 10, offer interesting insights into how Word2Vec captures relationships between characters across different Star Trek TV shows. Here's an analysis based on the provided results:\n",
    "\n",
    "    Observations:\n",
    "Higher Intra-show Similarities: For both models, the diagonal entries in the matrices (which represent average pairwise similarities within the same TV show) are consistently higher than the off-diagonal entries. This indicates that characters within the same show tend to have more similar contexts (as captured by Word2Vec) than characters across different shows, which is an expected and desired outcome when analyzing character relationships.\n",
    "\n",
    "    Comparison Between Models:\n",
    "Model with Window Size of 2: This model shows relatively high similarities both within and between shows, with intra-show similarities being the highest. The similarity scores are generally above 0.5, indicating a closer relationship between characters. This suggests that a smaller window size captures more immediate contextual relationships, potentially leading to a stronger association between characters who interact closely within the narratives of their respective shows.\n",
    "        \n",
    "Model with Window Size of 10: This model shows a much more significant distinction between intra-show and inter-show similarities. The intra-show similarities remain the highest, but the inter-show similarities drop significantly, especially compared to the model with a window size of 2. For example, similarities between \"ENT\" and other shows drop to values around 0.2 or lower, indicating a broader contextual gap captured by the larger window size.\n",
    "        \n",
    "    Analysis:\n",
    "Differentiation of TV Shows: The model with a window size of 10 differentiates characters of one TV show from characters of other TV shows more distinctly than the model with a window size of 2. This is evident from the significantly lower inter-show similarities in the model with the larger window size. The broader context captured with a window size of 10 helps the model to better understand and distinguish the unique narrative contexts of each show.\n",
    "\n",
    "Intra-show Character Relationships: Both models effectively capture intra-show relationships, as seen in the higher average similarities within shows. However, the model with a window size of 2 presents a less pronounced difference between intra-show and inter-show relationships, suggesting it captures more localized character interactions.\n",
    "\n",
    "    Conclusion:\n",
    "The model with a window size of 10 more effectively differentiates the characters of a TV show from characters of other TV shows, as indicated by the stark contrast in average similarities. This suggests that a larger window size may be more suitable for capturing the distinct narrative and thematic contexts of different TV shows, leading to clearer distinctions in character relationships across the Star Trek franchise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309568d8",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "\n",
    "\n",
    "Repeat task for for the role-column, which contains information of the role the characters\n",
    "represent in the tv show. Again, compare the inner vs. outer similarities within these groups.\n",
    "Which model works better for this task?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab3076d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations_with_replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "913dd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess character names (if necessary, based on previous steps)\n",
    "characters_df['Character'] = characters_df['Character'].str.lower().replace({\"o'brien\": \"obrien\", \"t'pol\": \"tpol\"}, regex=True)\n",
    "\n",
    "# Group characters by role\n",
    "role_groups = characters_df.groupby('Roles')['Character'].apply(list).to_dict()\n",
    "\n",
    "# Function to calculate average similarities based on roles for a given model\n",
    "def calculate_average_role_similarity(model, role_groups):\n",
    "    roles = list(role_groups.keys())\n",
    "    avg_similarity_matrix = pd.DataFrame(0, index=roles, columns=roles, dtype=float)\n",
    "    \n",
    "    for role1, role2 in combinations_with_replacement(roles, 2):\n",
    "        characters1 = role_groups[role1]\n",
    "        characters2 = role_groups[role2]\n",
    "        total_similarity = 0\n",
    "        count = 0\n",
    "        \n",
    "        for char1 in characters1:\n",
    "            for char2 in characters2:\n",
    "                # Ensure both characters are in the model's vocabulary\n",
    "                if char1 in model.wv.key_to_index and char2 in model.wv.key_to_index:\n",
    "                    similarity = model.wv.similarity(char1, char2)\n",
    "                    total_similarity += similarity\n",
    "                    count += 1\n",
    "        \n",
    "        # Calculate average similarity if there were valid comparisons\n",
    "        avg_similarity = total_similarity / count if count > 0 else float('nan')\n",
    "        avg_similarity_matrix.loc[role1, role2] = avg_similarity\n",
    "        if role1 != role2:\n",
    "            avg_similarity_matrix.loc[role2, role1] = avg_similarity  # Fill symmetric value\n",
    "    \n",
    "    return avg_similarity_matrix\n",
    "\n",
    "# Assuming 'model_window_2' and 'model_window_10' are your trained Word2Vec models\n",
    "avg_role_similarity_matrix_window_2 = calculate_average_role_similarity(model_window_2, role_groups)\n",
    "avg_role_similarity_matrix_window_10 = calculate_average_role_similarity(model_window_10, role_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af960e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captains</th>\n",
       "      <th>Engineers</th>\n",
       "      <th>First Officers</th>\n",
       "      <th>Nicknames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Captains</th>\n",
       "      <td>0.828997</td>\n",
       "      <td>0.606871</td>\n",
       "      <td>0.680319</td>\n",
       "      <td>0.310843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineers</th>\n",
       "      <td>0.606871</td>\n",
       "      <td>0.778255</td>\n",
       "      <td>0.610394</td>\n",
       "      <td>0.326840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Officers</th>\n",
       "      <td>0.680319</td>\n",
       "      <td>0.610394</td>\n",
       "      <td>0.730280</td>\n",
       "      <td>0.320958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicknames</th>\n",
       "      <td>0.310843</td>\n",
       "      <td>0.326840</td>\n",
       "      <td>0.320958</td>\n",
       "      <td>0.651628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Captains  Engineers  First Officers  Nicknames\n",
       "Captains        0.828997   0.606871        0.680319   0.310843\n",
       "Engineers       0.606871   0.778255        0.610394   0.326840\n",
       "First Officers  0.680319   0.610394        0.730280   0.320958\n",
       "Nicknames       0.310843   0.326840        0.320958   0.651628"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_role_similarity_matrix_window_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7298c668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captains</th>\n",
       "      <th>Engineers</th>\n",
       "      <th>First Officers</th>\n",
       "      <th>Nicknames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Captains</th>\n",
       "      <td>0.395027</td>\n",
       "      <td>0.210442</td>\n",
       "      <td>0.261030</td>\n",
       "      <td>0.052812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineers</th>\n",
       "      <td>0.210442</td>\n",
       "      <td>0.593059</td>\n",
       "      <td>0.259147</td>\n",
       "      <td>0.214536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Officers</th>\n",
       "      <td>0.261030</td>\n",
       "      <td>0.259147</td>\n",
       "      <td>0.375868</td>\n",
       "      <td>0.097544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicknames</th>\n",
       "      <td>0.052812</td>\n",
       "      <td>0.214536</td>\n",
       "      <td>0.097544</td>\n",
       "      <td>0.455250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Captains  Engineers  First Officers  Nicknames\n",
       "Captains        0.395027   0.210442        0.261030   0.052812\n",
       "Engineers       0.210442   0.593059        0.259147   0.214536\n",
       "First Officers  0.261030   0.259147        0.375868   0.097544\n",
       "Nicknames       0.052812   0.214536        0.097544   0.455250"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_role_similarity_matrix_window_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444b6ed",
   "metadata": {},
   "source": [
    "Analyzing the average cosine similarities for characters based on their roles within the Star Trek universe, two Word2Vec models with different window sizes (2 and 10) reveal distinct capabilities:\n",
    "\n",
    "Model with Window Size of 2: Excels at highlighting strong, role-specific contexts, demonstrated by higher inner-role similarities. It effectively captures the immediate textual context around character mentions, making it ideal for analyzing closely shared role characteristics.\n",
    "\n",
    "Model with Window Size of 10: Stands out in distinguishing between the unique narrative contexts of different roles. Lower between-role similarities indicate this model's superior differentiation capabilities, ideal for exploring how roles diverge across narratives.\n",
    "\n",
    "Conclusion: The choice between models hinges on the analytical goal. For in-depth exploration of role-specific contexts, the model with window size 2 is preferable. Conversely, for distinguishing between different roles’ narrative functions, the model with window size 10 offers clearer insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201bc8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
